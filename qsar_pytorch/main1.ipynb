{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## script that build qsar models.\n",
    "\n",
    "At first, calculate molecular descriptors.\n",
    "The code is follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pickle as cPickle\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import DataStructs\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.ML.Descriptors import MoleculeDescriptors\n",
    "from sklearn import preprocessing\n",
    " \n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "trainset = [mol for mol in Chem.SDMolSupplier(\"solubility.train.sdf\") if mol is not None]\n",
    "testset = [mol for mol in Chem.SDMolSupplier(\"solubility.test.sdf\") if mol is not None]\n",
    " \n",
    "nms = [x[0] for x in Descriptors._descList]\n",
    "calc = MoleculeDescriptors.MolecularDescriptorCalculator(nms)\n",
    "print(len(nms))\n",
    "\n",
    "trainDescrs = [calc.CalcDescriptors(x) for x in trainset]\n",
    "testDescrs  = [calc.CalcDescriptors(x) for x in testset]\n",
    "trainDescrs = np.array(trainDescrs)\n",
    "testDescrs = np.array(testDescrs)\n",
    " \n",
    "x_train_minmax = min_max_scaler.fit_transform( trainDescrs )\n",
    "x_test_minmax = min_max_scaler.fit_transform( testDescrs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes={'(A) low':0,'(B) medium':1,'(C) high':1}\n",
    "\n",
    "train_acts = np.array([classes[mol.GetProp(\"SOL_classification\")] for mol in trainset], dtype=\"int\")\n",
    "test_acts = np.array([classes[mol.GetProp(\"SOL_classification\")] for mol in testset], dtype=\"int\")\n",
    "\n",
    "dataset = ( (x_train_minmax, train_acts),(x_train_minmax, train_acts), (x_test_minmax, test_acts) )\n",
    "#tmp_dataset = np.array(dataset)\n",
    "#print (np.any(np.isnan(tmp_dataset)))\n",
    "\n",
    "f = open(\"rdk_sol_set_norm_descs.pkl\", \"wb\")\n",
    "cPickle.dump(dataset,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I could get train and test data set as pkl file.\n",
    "Next, build the model using scikit-learn\n",
    "The code build the model using RANDOMFOREST, SVM, Naive Bayes, Ristrict Bollzmann-SVM classifiler(RBS).\n",
    "Scikit-learn can join RBM-SVM using pipeline method.\n",
    "Model can save as pkl file using cPicke. (following code print results only. ;-) )\n",
    "Scikit-learn is very simple to use, and powerful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDPMFOREST\n",
      "[[101   1]\n",
      " [ 50 105]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.99      0.80       102\n",
      "           1       0.99      0.68      0.80       155\n",
      "\n",
      "    accuracy                           0.80       257\n",
      "   macro avg       0.83      0.83      0.80       257\n",
      "weighted avg       0.86      0.80      0.80       257\n",
      "\n",
      "0.8015564202334631\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "#from sklearn import cross_validation\n",
    "from sklearn import metrics\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "f = open(\"rdk_sol_set_norm_descs.pkl\", \"rb\")\n",
    "train, valid, test = cPickle.load(f)\n",
    "\n",
    "train_x, train_y = train\n",
    "test_x, test_y = test\n",
    "\n",
    "print (\"RANDPMFOREST\")\n",
    "nclf = RandomForestClassifier( n_estimators=100, max_depth=5, random_state=0, n_jobs=1 )\n",
    "nclf = nclf.fit( train_x, train_y )\n",
    "preds = nclf.predict( test_x )\n",
    "print (metrics.confusion_matrix(test_y, preds))\n",
    "print (metrics.classification_report(test_y, preds))\n",
    "accuracy = nclf.score(test_x, test_y)\n",
    "print (accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "[[ 97   5]\n",
      " [ 29 126]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.95      0.85       102\n",
      "           1       0.96      0.81      0.88       155\n",
      "\n",
      "    accuracy                           0.87       257\n",
      "   macro avg       0.87      0.88      0.87       257\n",
      "weighted avg       0.89      0.87      0.87       257\n",
      "\n",
      "0.867704280155642\n"
     ]
    }
   ],
   "source": [
    "print (\"SVM\")\n",
    "clf_svm = svm.SVC( gamma=0.001, C=100. )\n",
    "clf_svm = clf_svm.fit( train_x, train_y )\n",
    "preds_SVM = clf_svm.predict( test_x )\n",
    "print (metrics.confusion_matrix( test_y, preds_SVM ))\n",
    "print (metrics.classification_report( test_y, preds_SVM ))\n",
    "accuracy = clf_svm.score( test_x, test_y )\n",
    "print (accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB\n",
      "[[ 42  60]\n",
      " [ 16 139]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.41      0.53       102\n",
      "           1       0.70      0.90      0.79       155\n",
      "\n",
      "    accuracy                           0.70       257\n",
      "   macro avg       0.71      0.65      0.66       257\n",
      "weighted avg       0.71      0.70      0.68       257\n",
      "\n",
      "0.7042801556420234\n"
     ]
    }
   ],
   "source": [
    "print (\"NB\")\n",
    "gnb = GaussianNB()\n",
    "clf_NB = gnb.fit( train_x, train_y )\n",
    "preds_NB = clf_NB.predict( test_x )\n",
    "print (metrics.confusion_matrix( test_y, preds_NB ) )\n",
    "print (metrics.classification_report( test_y, preds_NB ) )\n",
    "accuracy = clf_NB.score( test_x, test_y )\n",
    "print (accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBM\n",
      "[BernoulliRBM] Iteration 1, pseudo-likelihood = -54.15, time = 0.24s\n",
      "[BernoulliRBM] Iteration 2, pseudo-likelihood = -54.07, time = 0.27s\n",
      "[BernoulliRBM] Iteration 3, pseudo-likelihood = -53.57, time = 0.25s\n",
      "[BernoulliRBM] Iteration 4, pseudo-likelihood = -50.35, time = 0.33s\n",
      "[BernoulliRBM] Iteration 5, pseudo-likelihood = -48.29, time = 0.32s\n",
      "[BernoulliRBM] Iteration 6, pseudo-likelihood = -49.30, time = 0.31s\n",
      "[BernoulliRBM] Iteration 7, pseudo-likelihood = -47.74, time = 0.28s\n",
      "[BernoulliRBM] Iteration 8, pseudo-likelihood = -48.52, time = 0.39s\n",
      "[BernoulliRBM] Iteration 9, pseudo-likelihood = -47.15, time = 0.30s\n",
      "[BernoulliRBM] Iteration 10, pseudo-likelihood = -49.40, time = 0.30s\n",
      "[BernoulliRBM] Iteration 11, pseudo-likelihood = -48.34, time = 0.31s\n",
      "[BernoulliRBM] Iteration 12, pseudo-likelihood = -47.81, time = 0.62s\n",
      "[BernoulliRBM] Iteration 13, pseudo-likelihood = -48.61, time = 0.32s\n",
      "[BernoulliRBM] Iteration 14, pseudo-likelihood = -46.24, time = 0.28s\n",
      "[BernoulliRBM] Iteration 15, pseudo-likelihood = -48.17, time = 0.29s\n",
      "[BernoulliRBM] Iteration 16, pseudo-likelihood = -46.88, time = 0.35s\n",
      "[BernoulliRBM] Iteration 17, pseudo-likelihood = -46.81, time = 0.47s\n",
      "[BernoulliRBM] Iteration 18, pseudo-likelihood = -46.06, time = 0.36s\n",
      "[BernoulliRBM] Iteration 19, pseudo-likelihood = -46.35, time = 0.29s\n",
      "[BernoulliRBM] Iteration 20, pseudo-likelihood = -47.16, time = 0.26s\n",
      "[[ 82  20]\n",
      " [ 30 125]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.80      0.77       102\n",
      "           1       0.86      0.81      0.83       155\n",
      "\n",
      "    accuracy                           0.81       257\n",
      "   macro avg       0.80      0.81      0.80       257\n",
      "weighted avg       0.81      0.81      0.81       257\n",
      "\n",
      "0.8054474708171206\n"
     ]
    }
   ],
   "source": [
    "print (\"RBM\")\n",
    "cls_svm2 = svm.SVC( gamma=0.001, C=100. )\n",
    "rbm = BernoulliRBM(random_state = 0, verbose = True)\n",
    "classifier = Pipeline( steps=[(\"rbm\", rbm), (\"cls_svm2\", cls_svm2)] )\n",
    "rbm.learning_rate = 0.06\n",
    "rbm.n_iter = 20\n",
    "rbm.n_compornents = 1000\n",
    "classifier.fit(train_x, train_y)\n",
    "pred_RBM = classifier.predict(test_x)\n",
    "print (metrics.confusion_matrix(test_y, pred_RBM) )\n",
    "print (metrics.classification_report(test_y, pred_RBM) )\n",
    "accuracy = classifier.score( test_x, test_y )\n",
    "print (accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
