{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting environmental carcinogens with logistic regression, knn, gradient boosting and molecular fingerprinting\n",
    "\n",
    "### Balancing imbalanced data, exploring accuracy metrics, and an introduction to cheminformatics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction and background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Tox 21?\n",
    "\n",
    "The Toxicology in the 21st Century program, or Tox21, is a unique collaboration between several federal agencies to develop new ways to rapidly test whether substances adversely affect human health. Substances assayed in Tox21 include a diverse range of products such as: commercial chemicals, pesticides, food additives/contaminants, and medical compounds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why the p53 protein?\n",
    "\n",
    "The p53 gene encodes a protein of the same name and is known as a tumor-suppressor protein. The p53 protein is expressed in cells when they undergo DNA damage — which can transform a normal cell into a cancerous one. To counteract the effects, p53 can cause growth arrest, repair DNA, or begin the process of cell death. Therefore, when DNA damage occurs, there is a significant increase in p53 expression. This increase in protein expression is a good indicator of irregular cell health. The Tox21 data was generated by testing cell lines which produce a florescent reporter gene product under the control of p53 cellular machinery. By measuring levels of the reporter gene product against various compounds, researchers were able to determine whether a compound was an agonist (activator) of the p53 pathway or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting agonists using molecular fingerprinting\n",
    "\n",
    "Fingerprinting is a way to represent molecular structure and properties as binary bit strings (0’s and 1's). This representation was initially developed and applied to searching databases for molecules with a specific substructure — but it can also be applied to machine learning. A hash function is a random number generator and is applied to each feature of a molecule, such as the types of bonds and molecules present, which means that they act as seeds to the function.\n",
    "\n",
    "The following image illustrates how a two molecules can have their similarity assessed (using The Tanimoto index) by generating molecular fingerprints. Each molecule first has the hash function applied to it and then a fingerprint is generated based on features. The fingerprint generator in the image below looks at a certain bond distance radius and the features within that distance.\n",
    "\n",
    "<img src=\"images/tanimoto.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of fingerprints\n",
    "\n",
    "This project will be using four different types of fingerprints and comparing their predictive strength.\n",
    "\n",
    "\n",
    "**Morgan circular fingerprint** —  This fingerprint is part of the Extended-Connectivity Fingerprints (ECFPs) family and are generated using the Morgan algorithm [2,3]. These fingerprints represent molecular structures and the presence of substructures by means of circular atom neighborhoods (bond radius). Another important feature is their ability to determine the absence or presence of molecular functionality, which can further help discriminate when classifying molecules.\n",
    "<br>\n",
    "<br>\n",
    "<img src=\"images/morgan.png\">\n",
    "<br>\n",
    "<br>\n",
    "**Daylight-like fingerprint** — This fingerprint generator (using RDKit) produces a fingerprint similar to the fingerprint generated using the Daylight fingerprinting algorithm. An oversimplified explanation: the algorithm hashes bonds along a path within a molecule (topological pathways)[4][5]. The image below shows how bond paths are identified and described.\n",
    "<br>\n",
    "<br>\n",
    "<img src=\"images/daylight.png\">\n",
    "<br>\n",
    "<br>\n",
    "**Atom-pair fingerprint** — The atom-pair fingerprint is constructed using — as the name suggests — pairs of atoms (as features) as well as their topological distances. The atom-pair fingerprint is generated as shown below by first identifying heavy atoms and the shortest distance between them. Features of the individual atoms within a pair (like the number of bonds) are encoded . These encoded features are then converted into bit strings and represented as one number. This concatenated string of integers is then passed to the hash function which then assigns it as a 1 or 0.\n",
    "<br>\n",
    "<br>\n",
    "<img src=\"images/ap.png\">\n",
    "<br>\n",
    "<br>\n",
    "**Topological torsion fingerprints** — are 2D structural fin­gerprints that are generated by identifying bond paths of four non-hydrogen atoms. These four-path fragments then have their features, such as the number of π electrons of each atom, atomic type and number of non-hydrogen branches calculated. Each atom is characterized by 8 bits and the 4 atoms have their bits stored in a 32-bit array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data\n",
    "\n",
    "The Tox21 data is already labeled with active (1) and inactive (0) states so there really isn’t much to do in this step other than load, format column names, and generate mol files (these files are generally classified as data files that contain molecular data information, atom, bonds, coordinates and connectivity information) for each molecule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general and data handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "# Required RDKit modules\n",
    "import rdkit as rd\n",
    "from rdkit.Chem.Fingerprints import FingerprintMols\n",
    "from rdkit import RDConfig\n",
    "from rdkit.Chem import PandasTools\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit.Chem import rdFingerprintGenerator\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import AllChem as Chem\n",
    "from rdkit.Chem.rdMolDescriptors import GetAtomPairFingerprint\n",
    "from rdkit.Chem.AtomPairs import Torsions\n",
    "\n",
    "# modeling\n",
    "import sklearn as sk\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Graphing\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and formatting\n",
    "\n",
    "To follow along, edit the path to where the data is on your machine. We load an sdf file which is a structure-data file and contains associated data for compounds. We actually don't need these details as they wont add to classifying p53 agonists, hence we drop them. For example the \"formula column\" gives us no usable information at all since its the empirical formula and doesn't contain the valuable structural information a SMILES string provides. We do need mol representations of the molecules so we generate those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit ERROR: [21:51:33] Explicit valence for atom # 2 Si, 8, is greater than permitted\n",
      "RDKit ERROR: [21:51:33] ERROR: Could not sanitize molecule ending on line 104652\n",
      "RDKit WARNING: [21:51:37] WARNING: not removing hydrogen atom without neighbors\n",
      "RDKit ERROR: [21:51:33] ERROR: Explicit valence for atom # 2 Si, 8, is greater than permitted\n",
      "RDKit ERROR: [21:51:39] Explicit valence for atom # 2 Si, 8, is greater than permitted\n",
      "RDKit ERROR: [21:51:39] ERROR: Could not sanitize molecule ending on line 400224\n",
      "RDKit ERROR: [21:51:39] ERROR: Explicit valence for atom # 2 Si, 8, is greater than permitted\n",
      "RDKit ERROR: [21:51:40] Explicit valence for atom # 3 Mg, 4, is greater than permitted\n",
      "RDKit ERROR: [21:51:40] ERROR: Could not sanitize molecule ending on line 446411\n"
     ]
    }
   ],
   "source": [
    "sdfFile = 'sr-p53.sdf'\n",
    "p53 = PandasTools.LoadSDF(sdfFile,smilesName='SMILES',molColName='Molecule', includeFingerprints=True)\n",
    "p53 = p53.drop(['DSSTox_CID', 'FW', \"Formula\", 'Molecule'], axis=1)\n",
    "#p53.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mol generation and unique records\n",
    "\n",
    "We should also ensure that there aren't any duplicates in the data. This data set in particular has a total number of 8629 records and only  6826 unique records, meaning that ~20% of the data is duplicated and needs to be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [21:51:49] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    }
   ],
   "source": [
    "p53[\"mol\"] = [Chem.MolFromSmiles(x) for x in p53[\"SMILES\"]]\n",
    "#frame1['MFP2BV'] = [Chem.GetMorganFingerprintAsBitVect(x, 2, nBits=1024) for x in frame1[\"mol\"]]\n",
    "#frame1[\"bitstring\"] = [x.ToBitString for x in frame1[\"MFP2BV\"]]\n",
    "\n",
    "#count the nummber of unique rows in the SMILES column\n",
    "p53['SMILES'].nunique()\n",
    "\n",
    "#Compare that with total rows\n",
    "p53['SMILES'].count()\n",
    "\n",
    "#we can drop the duplicated ones\n",
    "p53 = p53.drop_duplicates(['SMILES'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fingerprint generation\n",
    "\n",
    "Here is an example of fingerprint generation using the Morgan algorithm. A fingerprint is generated for each compound in the \"mol\" column with a radius of 2 and a bit length of 2048. A list with the same parameters is also generated for each mol. A for loop then iterates through the loop to create a numpy array and append a new list denoted by \"np\" in the name. These lists will become our x variables when running the classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a column for the morgan fingerprints\n",
    "p53[\"morg_fp\"] = [Chem.GetMorganFingerprintAsBitVect(m, 2, nBits = 2048) for m in p53['mol']]\n",
    "\n",
    "# generate morgan fingeprints with radius 2 contained in a list\n",
    "morg_fp = [Chem.GetMorganFingerprintAsBitVect(m, 2, nBits = 2048) for m in p53['mol']]\n",
    "\n",
    "# convert the RDKit explicit vectors into numpy arrays\n",
    "morg_fp_np = []\n",
    "for fp in morg_fp:\n",
    "    arr = np.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    morg_fp_np.append(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a column for the RDKit fingerprints\n",
    "p53[\"rd_fp\"] = [Chem.RDKFingerprint(m) for m in p53[\"mol\"]]\n",
    "\n",
    "#The fingerprinting algorithm used is similar to that used in the Daylight fingerprinter\n",
    "rd_fp = [Chem.RDKFingerprint(m) for m in p53[\"mol\"]]\n",
    "\n",
    "rd_fp_np = []\n",
    "for fp in rd_fp:\n",
    "    arr = np.zeros((1,))\n",
    "    DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "    rd_fp_np.append(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a column for the Atom-pair fingerprints\n",
    "p53[\"AP_fp\"] = [Chem.GetHashedAtomPairFingerprintAsBitVect(m) for m in p53[\"mol\"]]\n",
    "\n",
    "#get atom-par fingerprints\n",
    "AP_fp = [Chem.GetHashedAtomPairFingerprintAsBitVect(m) for m in p53[\"mol\"]]\n",
    "\n",
    "#convert the RDKit explicit vectors into numpy arrays\n",
    "AP_fp_np = []\n",
    "for fp in AP_fp:\n",
    "  arr = np.zeros((1,))\n",
    "  DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "  AP_fp_np.append(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a column for the topological torsion fingerprints\n",
    "p53[\"torsion_fp\"] = torsion_fp = [Chem.GetHashedTopologicalTorsionFingerprintAsBitVect(m) for m in p53[\"mol\"]]\n",
    "\n",
    "#get topological torsion fingerprints\n",
    "torsion_fp = [Chem.GetHashedTopologicalTorsionFingerprintAsBitVect(m) for m in p53[\"mol\"]]\n",
    "\n",
    "#convert the RDKit explicit vectors into numpy arrays\n",
    "torsion_fp_np = []\n",
    "for fp in torsion_fp:\n",
    "  arr = np.zeros((1,))\n",
    "  DataStructs.ConvertToNumpyArray(fp, arr)\n",
    "  torsion_fp_np.append(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setting the x and y variables:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#morgan fingerprints\n",
    "x_morg = morg_fp_np\n",
    "\n",
    "#daylight-like fingerprints\n",
    "x_rd = rd_fp_np\n",
    "\n",
    "#atom-pair fingerprints\n",
    "x_AP = AP_fp_np\n",
    "\n",
    "#topological torsion fingerprints\n",
    "x_torsion = torsion_fp_np\n",
    "\n",
    "#classification labels\n",
    "y = p53.Active.values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling: Are the classes balanced?\n",
    "\n",
    "When the classification labels (in our case: active = 1; inactive = 0) are skewed in proportion, bias is introduced into the model. For example, if the data set contains 95% active labels then the model will likely classify an inactive molecule as an active one, simply put, the accuracy will reflect the class class distribution. Determining if class imbalance is straight forward — count the distribution of labels. Once we determine how prevalent the minority class is in our data set, we can move forward with balancing it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store the activity labels of all compounds\n",
    "y = p53.Active.values\n",
    "\n",
    "#return the count for each unique value (0 and 1)\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "dict(zip(unique, counts))\n",
    "\n",
    "#plot the label counts \n",
    "count1 = sns.catplot(x=\"Active\", kind=\"count\", palette=\"ch:.25\", data=p53)\n",
    "\n",
    "#I added the count of class labels as the title here\n",
    "count1.fig.suptitle('0: 6406, 1: 420')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The count plot above shows us that there is a disproportionate distribution of classes in our data, a ratio of 15:1 (inactive to active) meaning approximately ~93.84% of our classes being  inactive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods of class balancing\n",
    "\n",
    "There are two ways to balance the data: over-sampling and under-sampling. Over sampling brings balance by generating synthetic data points using using one of many algorithms. The one we will use today is a variation of the SMOTE (Synthetic Minority Over-Sampling Technique) algorithm. SMOTE works by searching for the k-nearest neighbors for a given point of data and then generates data points along the line between neighbors. Since these points fall on a line between the real data points, there is some correlation, which is why we will use the ADASYN algorithm (Adaptive Synthetic). ADASYN works essentially the same way SMOTE does, however, it adds small randomly generated values to the points to increase variance and simulate more realistic data.\n",
    "\n",
    "**note** - I opted not to use under-sampling since it balances the classes by removing data points from the majority class and therefore there is a loss of data, possibly affecting the classifier's ability to discriminate.\n",
    "\n",
    "<img src=\"images/adasyn.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_morg_rsmp, y_morg_rsmp = ADASYN().fit_resample(x_morg, y)\n",
    "morg_sample_count = sorted(Counter(y_morg_rsmp).items())\n",
    "\n",
    "x_rd_rsmp, y_rd_rsmp = ADASYN().fit_resample(x_rd, y)\n",
    "rd_sample_count = sorted(Counter(y_rd_rsmp).items())\n",
    "\n",
    "x_AP_rsmp, y_AP_rsmp = ADASYN().fit_resample(x_AP, y)\n",
    "AP_sample_count = sorted(Counter(y_rd_rsmp).items())\n",
    "\n",
    "x_torsion_rsmp, y_torsion_rsmp = ADASYN().fit_resample(x_torsion, y)\n",
    "torsion_sample_count = sorted(Counter(y_rd_rsmp).items())\n",
    "\n",
    "print(\"Morgan distribution:\", morg_sample_count, \n",
    "      \"Daylight-like distribution:\", rd_sample_count, \n",
    "      \"Atom-pair distribution:\", AP_sample_count, \n",
    "      \"Torsion distribution:\", torsion_sample_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can plot one of the re-sampled distributions to visually represent class balance:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_morg_rsmp_df = pd.DataFrame(y_morg_rsmp, columns=['Active'])\n",
    "sns.catplot(x=\"Active\", kind=\"count\", palette=\"ch:.25\", data=y_morg_rsmp_df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "The logistic regression algorithm classifies a categorical response (outcome) variable between 1 and 0 based on its relationship with predictive features. In contrast, linear regression outputs response variables that are continuous and can be any real number. Most importantly, linear regression does not output probabilities and instead fits the best hyperplane. Therefore logistic regression is the natural choice for a binary classification problem such as ours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating training, testing, and validation test sets\n",
    "\n",
    "In order to train, test, and then test again we need to create three separate data partitions. The training data will be used to train our model - essentially the model will use this data to learn which fingerprints (the 2048 bit patterns) likely belong to p53 agonists. The test set will be used to evaluate the accuracy of our model, and lastly a validation set will be used as unbiased data set to test the predictive ability of our model.\n",
    "Our data will be split into 85/15 train/test sets and then the training data will be further split into an 85/15 train/validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Partitioning the data into an 85/15 train/test split\n",
    "x_morg_train, x_morg_test, y_morg_train, y_morg_test = train_test_split(x_morg_rsmp, y_morg_rsmp, test_size=0.15, random_state=1)\n",
    "#The training data is further split into an 80/15 train/validtion split \n",
    "x_morg_train, x_morg_val, y_morg_train, y_morg_val = train_test_split(x_morg_train, y_morg_train, test_size=0.15, random_state=1)\n",
    "\n",
    "x_rd_train, x_rd_test, y_rd_train, y_rd_test = train_test_split(x_rd_rsmp, y_rd_rsmp, test_size=0.15, random_state=1)\n",
    "x_rd_train, x_rd_val, y_rd_train, y_rd_val = train_test_split(x_rd_train, y_rd_train, test_size=0.15, random_state=1)\n",
    "\n",
    "x_AP_train, x_AP_test, y_AP_train, y_AP_test = train_test_split(x_AP_rsmp, y_AP_rsmp, test_size=0.15, random_state=1)\n",
    "x_AP_train, x_AP_val, y_AP_train, y_AP_val = train_test_split(x_AP_train, y_AP_train, test_size=0.15, random_state=1)\n",
    "\n",
    "x_torsion_train, x_torsion_test, y_torsion_train, y_torsion_test = train_test_split(x_torsion_rsmp, y_torsion_rsmp, test_size=0.15, random_state=1)\n",
    "x_torsion_train, x_torsion_val, y_torsion_train, y_torsion_val = train_test_split(x_torsion_train, y_torsion_train, test_size=0.15, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation and model fitting\n",
    "\n",
    "Cross validation is a statistical technique to reduce the risk of over-fitting the data. Over-fitting occurs when the classifier memorizes the data and fits noise and error instead of the underlying relationship between variables. This can occur if the model is overly complex and if there is limited data to train on. Our model doesn't seem to suffer from these two limitations but its good practice to perform cross validation anyway.\n",
    "\n",
    "The top image illustrate how a model may \"memorize\" and essentially fit the data too well. The bottom image shows how cross validation creates 10 folds, each of which is split into a test and train set to fit a model, and then averages the error from each fold.\n",
    "\n",
    "<img src=\"images/overfit_cv.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following lines of code show how to perform logistic regression, obtain cross validations scores for each fold (just one iteration on the training data to estimate scores using the chosen classifier). We then model logistic regression over 1000 iterations while performing k-fold (10) cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set our linear regression function\n",
    "lr = LogisticRegression(solver = 'lbfgs', max_iter = 1000)\n",
    "#fit the data \n",
    "#perform 10 fold crossvalidation to estimate accuracy of model\n",
    "accuracy_morg = cross_val_score(lr, x_morg_train, y_morg_train, scoring='accuracy', cv = 10)\n",
    "\n",
    "#get the mean of each fold \n",
    "print(\"Accuracy of Model with Cross Validation is:\",accuracy_morg.mean() * 100, \"(+/- %0.2f)\" % accuracy_morg.std())\n",
    "\n",
    "#Create our model using 10 fold cross valiation, lbfgs, and 1000 iterations - and fit the data to out training set\n",
    "lr_morg_ = LogisticRegressionCV(cv=10, solver = 'lbfgs', max_iter = 1000).fit(x_morg_train, y_morg_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the rest of the fingerprints we can simply write a function to model the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to train the logistic regression classifier on given x and y training sets\n",
    "def lrCV_model(x_train, y_train):\n",
    "    lr = LogisticRegression(solver = 'lbfgs', max_iter = 650)\n",
    "    model_accuracy = cross_val_score(lr, x_train, y_train, scoring='accuracy', cv = 5)\n",
    "    accuracy_printout = \"Accuracy of Model with Cross Validation is:\",model_accuracy.mean() * 100, \"(+/- %0.2f)\" % model_accuracy.std()\n",
    "    lr_fit = LogisticRegressionCV(cv=5, solver = 'lbfgs', max_iter = 650, multi_class = \"ovr\", n_jobs = -1).fit(x_train, y_train)\n",
    "    \n",
    "    return lr_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train logistic regression models for all fingerprints\n",
    "lr_morg = lrCV_model(x_morg_train, y_morg_train)\n",
    "lr_rd = lrCV_model(x_rd_train, y_rd_train)\n",
    "lr_AP = lrCV_model(x_AP_train, y_AP_train)\n",
    "lr_torsion = lrCV_model(x_torsion_train, y_torsion_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Metrics and prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set predictions and confusion matrix\n",
    "\n",
    "A confusion matrix is a table which describes the performance of the trained model on test data. There are four quadrants comprising the matrix:\n",
    "\n",
    "  **true positives (TP):** These are compounds that were predicted positive (active p53 agonist) and actually are positive.\n",
    "\n",
    "   **true negatives (TN):** These compounds were predicted to be inactive and actually are inactive.\n",
    "\n",
    "   **false positives (FP):** Cases where the compounds are predicted to be active but are actually inactive (Type I error).\n",
    "\n",
    "   **false negatives (FN):** Cases where the compounds are predicted to be inactive but are actually active (Type II error)\n",
    "\n",
    "We can plot the confusion matrix for both test and validation set predictions along with accuracy - which is determined through (TP +TN)/Total cases. The confusion matrix on the left is that of the test set predictions and the right is for the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting using the test set and creating a confusion matrix\n",
    "predictions_morg_test = lr_morg.predict(x_morg_test)\n",
    "\n",
    "#confustion matrix for test set predictions\n",
    "cm_morg_test = metrics.confusion_matrix(y_morg_test, predictions_morg_test)\n",
    "\n",
    "print(cm_morg_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validation set predictions and confusion matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting using the validation set and creating a confusion matrix\n",
    "predictions_morg_val = lr_morg.predict(x_morg_val)\n",
    "\n",
    "#confustion matrix for validation set predictions\n",
    "cm_morg_val = metrics.confusion_matrix(y_morg_val, predictions_morg_val)\n",
    "\n",
    "print(cm_morg_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model accuracy on test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_morg_train = lr_morg.score(x_morg_train, y_morg_train)\n",
    "print('Accuracy of logistic regression classifier on train set:', score_morg_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model accuracy on test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_morg_test = lr_morg.score(x_morg_test, y_morg_test)\n",
    "print('Accuracy of logistic regression classifier on test set:', score_morg_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model accuracy on validation set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_morg_val = lr_morg.score(x_morg_val, y_morg_val)\n",
    "print('Accuracy of logistic regression classifier on test set:', score_morg_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_morg_val, predictions_morg_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,9))\n",
    "sns.heatmap(cm_morg_test, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "all_sample_title = 'Accuracy Score: {0}'.format(score_morg_test)\n",
    "plt.title(all_sample_title, size = 15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validation set confusion matrix plotted**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,9))\n",
    "sns.heatmap(cm_morg_val, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
    "plt.ylabel('Actual label');\n",
    "plt.xlabel('Predicted label');\n",
    "all_sample_title = 'Accuracy Score: {0}'.format(score_morg_val)\n",
    "plt.title(all_sample_title, size = 15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daylight-like fingerprint - logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting using the test set and creating a confusion matrix\n",
    "predictions_rd_test = lr_rd.predict(x_rd_test)\n",
    "\n",
    "#confustion matrix for test set predictions\n",
    "cm_rd_test = metrics.confusion_matrix(y_rd_test, predictions_rd_test)\n",
    "\n",
    "#predicting using the validation set and creating a confusion matrix\n",
    "predictions_rd_val = lr_rd.predict(x_rd_val)\n",
    "\n",
    "#confustion matrix for test validation predictions\n",
    "cm_rd_val = metrics.confusion_matrix(y_rd_val, predictions_rd_val)\n",
    "\n",
    "print(cm_rd_val)\n",
    "\n",
    "score_rd_train = lr_rd.score(x_rd_train, y_rd_train)\n",
    "print('Accuracy of logistic regression classifier on train set:', score_rd_train)\n",
    "\n",
    "score_rd_test = lr_rd.score(x_rd_test, y_rd_test)\n",
    "print('Accuracy of logistic regression classifier on test set:', score_rd_test)\n",
    "\n",
    "score_rd_val = lr_rd.score(x_rd_val, y_rd_val)\n",
    "print('Accuracy of logistic regression classifier on validation set:', score_rd_val)\n",
    "\n",
    "print(classification_report(y_rd_val, predictions_rd_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atom-pair fingerprint - logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting using the test set and creating a confusion matrix\n",
    "predictions_AP_test = lr_AP.predict(x_AP_test)\n",
    "\n",
    "#confustion matrix for test set predictions\n",
    "cm_AP_test = metrics.confusion_matrix(y_AP_test, predictions_AP_test)\n",
    "\n",
    "print(cm_AP_test)\n",
    "\n",
    "#predicting using the validation set and creating a confusion matrix\n",
    "predictions_AP_val = lr_AP.predict(x_AP_val)\n",
    "\n",
    "#confustion matrix for test validation predictions\n",
    "cm_AP_val = metrics.confusion_matrix(y_AP_val, predictions_AP_val)\n",
    "\n",
    "print(cm_AP_val)\n",
    "\n",
    "score_AP_train = lr_AP.score(x_AP_train, y_AP_train)\n",
    "print('Accuracy of logistic regression classifier on train set:', score_AP_train)\n",
    "\n",
    "score_AP_test = lr_AP.score(x_AP_test, y_AP_test)\n",
    "print('Accuracy of logistic regression classifier on test set:', score_AP_test)\n",
    "\n",
    "score_AP_val = lr_AP.score(x_AP_val, y_AP_val)\n",
    "print('Accuracy of logistic regression classifier on validation set:', score_AP_val)\n",
    "\n",
    "print(classification_report(y_AP_val, predictions_AP_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topological torsion fingerprint - logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting using the test set and creating a confusion matrix\n",
    "predictions_torsion_test = lr_torsion.predict(x_torsion_test)\n",
    "\n",
    "#confustion matrix for test set predictions\n",
    "cm_torsion_test = metrics.confusion_matrix(y_torsion_test, predictions_torsion_test)\n",
    "\n",
    "print(cm_torsion_test)\n",
    "\n",
    "#predicting using the validation set and creating a confusion matrix\n",
    "predictions_torsion_val = lr_torsion.predict(x_torsion_val)\n",
    "\n",
    "#confustion matrix for test validation predictions\n",
    "cm_torsion_val = metrics.confusion_matrix(y_torsion_val, predictions_torsion_val)\n",
    "\n",
    "print(cm_torsion_val)\n",
    "\n",
    "score_torsion_train = lr_torsion.score(x_torsion_train, y_torsion_train)\n",
    "print('Accuracy of logistic regression classifier on train set:', score_torsion_train)\n",
    "\n",
    "score_torsion_test = lr_torsion.score(x_torsion_test, y_torsion_test)\n",
    "print('Accuracy of logistic regression classifier on test set:', score_torsion_test)\n",
    "\n",
    "score_torsion_val = lr_torsion.score(x_torsion_val, y_torsion_val)\n",
    "print('Accuracy of logistic regression classifier on validation set:', score_torsion_val)\n",
    "\n",
    "print(classification_report(y_torsion_val, predictions_torsion_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-nearest neighbor\n",
    "\n",
    "The k-nearest neighbor algorithm (knn) takes a data point and looks at the k closest data points (k =7 would mean the 7 nearest), this data point is then labeled 0 or 1 according to the majority label of the k closest points. For example, if given a point of data with k=7 and the closest points happen to be five 0's and two 1's then the point would be classified as 0 (inactive).\n",
    "\n",
    "Knn performs best when working with fewer features, in turn resulting in lower chances of over-fitting. Normally we would have to perform PCA or another form of dimension reduction, however since we're using a single predictive feature we don't need to.\n",
    "\n",
    "<img src=\"images/knn.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid searching and model fitting\n",
    "\n",
    "Perform a grid search with cross validation to determine the optimal number of neighbors for our data. We will test 9 candidate numbers (3, 5, 7, 9, 11, 13, 15, 17, 19) and perform a 5 fold cross validation. This however may take a while since 9 neighbors x 5-fold validation for each amounts to 45 fits. The k-fold can be reduced so that we can keep a decent range of neighbors to try.\n",
    "\n",
    "The grid search suggests that the best number of neighbors to use is 3.\n",
    "\n",
    "**Note: set \"n_jobs\" to -1 - this allows for parallel processing with max CPU usage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "grid_params = {'n_neighbors': [3, 5, 7, 9, 11, 13, 15, 17, 19], 'weights': ['distance'], 'metric': ['euclidean']}\n",
    "knn_cv = GridSearchCV(knn, grid_params, cv=2, verbose = 1, n_jobs = -1)\n",
    "\n",
    "knn_morg = knn_cv.fit(x_morg_train, y_morg_train)\n",
    "\n",
    "knn_cv.best_params_\n",
    "knn_cv.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test out a range of k neighbors numbers we can fit different fingerprint data with varying k values. Using the Atom-pair training data I tested k = 3, 5, 7, 9 which resulted in following accuracy scores in order:\n",
    "\n",
    "0.846<br>\n",
    "0.846<br>\n",
    "0.815<br>\n",
    "0.785<br>\n",
    "\n",
    "It seems that 3 and 5 had the same scores, however 3 was likely chosen due to less computation time. Now to finish off, train the models with k=3 and compute their accuracy scores on first the test data and then validation data\n",
    "To test out a range of k neighbors numbers we can fit different fingerprint data with varying k values. Using the Atom-pair training data I tested k = 3, 5, 7, 9 which resulted in following accuracy scores in order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_3n = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_AP = knn3.fit(x_AP_train, y_AP_train)\n",
    "\n",
    "knn_5n = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_AP5 = knn_5n.fit(x_AP_train, y_AP_train)\n",
    "\n",
    "knn_7n = KNeighborsClassifier(n_neighbors=7)\n",
    "knn_AP7 = knn_7n.fit(x_AP_train, y_AP_train)\n",
    "\n",
    "knn_9n = KNeighborsClassifier(n_neighbors=9)\n",
    "knn_AP9 = knn_9n.fit(x_AP_train, y_AP_train)\n",
    "\n",
    "knn_AP_3n = knn_AP.score(x_AP_test, y_AP_test)\n",
    "print(knn_AP_3n)\n",
    "knn_AP_5n = knn_AP5.score(x_AP_test, y_AP_test)\n",
    "print(knn_AP_5n)\n",
    "knn_AP_7n = knn_AP7.score(x_AP_test, y_AP_test)\n",
    "print(knn_AP_7n)\n",
    "knn_AP_9n = knn_AP9.score(x_AP_test, y_AP_test)\n",
    "print(knn_AP_9n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the models and writing a function for scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn3 = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "knn_morg = knn3.fit(x_morg_train, y_morg_train)\n",
    "knn_rd = knn3.fit(x_rd_train, y_rd_train)\n",
    "knn_AP = knn3.fit(x_AP_train, y_AP_train)\n",
    "knn_torsion = knn3.fit(x_torsion_train, y_torsion_train)\n",
    "\n",
    "def mod_acc_knn(x_train, y_train, x_test, y_test):\n",
    "    knn3 = KNeighborsClassifier(n_neighbors=3)\n",
    "    knn_fp = knn3.fit(x_train, y_train)\n",
    "    score_fp_test_knn = knn_fp.score(x_test, y_test)\n",
    "    return score_fp_test_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### knn training data accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_morg_acc_train = mod_acc_knn(x_morg_train, y_morg_train, x_morg_train, y_morg_train)\n",
    "print(knn_morg_acc_train)\n",
    "knn_rd_acc_train = mod_acc_knn(x_rd_train, y_rd_train, x_rd_train, y_rd_train)\n",
    "print(knn_rd_acc_train)\n",
    "knn_AP_acc_train = mod_acc_knn(x_AP_train, y_AP_train, x_AP_train, y_AP_train)\n",
    "print(knn_AP_acc_train)\n",
    "knn_torsion_acc_train = mod_acc_knn(x_torsion_train, y_torsion_train, x_torsion_train, y_torsion_train)\n",
    "print(knn_torsion_acc_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### knn test data accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_morg_acc_test = mod_acc_knn(x_morg_train, y_morg_train, x_morg_test, y_morg_test)\n",
    "print(knn_morg_acc_test)\n",
    "knn_rd_acc_test = mod_acc_knn(x_rd_train, y_rd_train, x_rd_test, y_rd_test)\n",
    "print(knn_rd_acc_test)\n",
    "knn_AP_acc_test = mod_acc_knn(x_AP_train, y_AP_train, x_AP_test, y_AP_test)\n",
    "print(knn_AP_acc_test)\n",
    "knn_torsion_acc_test = mod_acc_knn(x_torsion_train, y_torsion_train, x_torsion_test, y_torsion_test)\n",
    "print(knn_torsion_acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### knn validation data accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_morg_acc_val = mod_acc_knn(x_morg_train, y_morg_train, x_morg_val, y_morg_val)\n",
    "print(knn_morg_acc_val)\n",
    "knn_rd_acc_val = mod_acc_knn(x_rd_train, y_rd_train, x_rd_val, y_rd_val)\n",
    "print(knn_rd_acc_val)\n",
    "knn_AP_acc_val = mod_acc_knn(x_AP_train, y_AP_train, x_AP_val, y_AP_val)\n",
    "print(knn_AP_acc_val)\n",
    "knn_torsion_acc_val = mod_acc_knn(x_torsion_train, y_torsion_train, x_torsion_val, y_torsion_val)\n",
    "print(knn_torsion_acc_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have fit a single model to the training data for each classier. Gradient boosting combines many individual models to create a single accurate one - this is known as an ensemble. Boosting is the method used to create an ensemble. It works by fitting the data with an initial model, then a subsequent model is built which works on accurately predicting the labels that the initial model classified incorrectly. Essentially, every subsequent model works to minimize the prediction error of the previous model which leads to an overall decrease in prediction error. Therefore predictions made by the final model are the result of the weighted sum of predictions calculated by all previous models.\n",
    "\n",
    "<img src=\"images/boost.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid searching and model training, and metrics\n",
    "\n",
    "Perform a grid search to tune parameters as we've done before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set search parameters\n",
    "params_gb = {\n",
    "    \"loss\":[\"deviance\"],\n",
    "    \"learning_rate\": [1.0],\n",
    "    \"min_samples_split\": np.linspace(0.1, 0.5, 12),\n",
    "    \"min_samples_leaf\": np.linspace(0.1, 0.5, 12),\n",
    "    \"max_depth\":[3,5,7],\n",
    "    \"max_features\":[\"sqrt\"],\n",
    "    \"criterion\": [\"friedman_mse\"],\n",
    "    \"subsample\":[0.5, 0.75, 0.95],\n",
    "    \"n_estimators\":[100]\n",
    "    }\n",
    "\n",
    "#initialize grid seach\n",
    "gb = GridSearchCV(GradientBoostingClassifier(), params_gb, cv=2, n_jobs=-1, verbose = 2)\n",
    "#train the model while tuning \n",
    "gb_morg = gb.fit(x_morg_train, y_morg_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the accuracy on the test and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gb_morg.score(x_morg_train, y_morg_train))\n",
    "print(gb_morg.score(x_morg_test, y_morg_test))\n",
    "print(gb_morg.score(x_morg_val, y_morg_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize grid seach\n",
    "gb = GridSearchCV(GradientBoostingClassifier(), params_gb, cv=2, n_jobs=-1, verbose = 2)\n",
    "#train the model while tuning \n",
    "gb_rd = gb.fit(x_rd_train, y_rd_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gb_rd.score(x_rd_train, y_rd_train))\n",
    "print(gb_rd.score(x_rd_test, y_rd_test))\n",
    "print(gb_rd.score(x_rd_val, y_rd_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize grid seach\n",
    "gb = GridSearchCV(GradientBoostingClassifier(), params_gb, cv=2, n_jobs=-1, verbose = 2)\n",
    "#train the model while tuning \n",
    "gb_AP = gb.fit(x_AP_train, y_AP_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gb_AP.score(x_AP_train, y_AP_train))\n",
    "print(gb_AP.score(x_AP_test, y_AP_test))\n",
    "print(gb_AP.score(x_AP_val, y_AP_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize grid seach\n",
    "gb = GridSearchCV(GradientBoostingClassifier(), params_gb, cv=2, n_jobs=-1, verbose = 2)\n",
    "#train the model while tuning \n",
    "gb_torsion = gb.fit(x_torsion_train, y_torsion_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gb_torsion_3.score(x_torsion_train, y_torsion_train))\n",
    "print(gb_torsion_3.score(x_torsion_test, y_torsion_test))\n",
    "print(gb_torsion_3.score(x_torsion_val, y_torsion_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUC values and F1-scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUC\n",
    "\n",
    "The Area Under Curve (AUC) value is another measure to evaluate the performance of a model on a binary classification task and is one of the most widely used metrics for evaluation. Two properties of a given model are needed to calculate the AUC - sensitivity and specificity. Sensitivity is the proportion of correctly classified positive points of data compared to all data points classified as positive. Sensitivity is the proportion of data points that were correctly classified as negative compared to all data points classified as negative.\n",
    "\n",
    "1. Sensitivity of a model: True positive / (False Negative + True positive).<br>\n",
    "2. Specificity of a model: True negative / (False positive + True negative).\n",
    "\n",
    "When the true positive rate is plotted against the false positive rate, the AUC of this curve can be calculated and essentially scores the ability of the model to distinguish between the two classes. A higher AUC means that molecules classified as p53 agonists are indeed more likely to be agonists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc_calc(x_val, y_val, model):\n",
    "    # Probability predictions using validation data\n",
    "    prob = model.predict_proba(x_val)\n",
    "    # Correct probability predictions\n",
    "    prob = prob[:, 1]\n",
    "    # Calculate area under the curve with validation data labels and correct predicted probabilities\n",
    "    auc = metrics.roc_auc_score(y_val, prob)\n",
    "    # Return the AUC score with 6 figures\n",
    "    return 'AUC: %.6f' % auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Morgan fingerprint auc values for all three models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morg_lr_auc = auc_calc(x_morg_val, y_morg_val, lr_morg)\n",
    "print(\"AUC using logistic regression: \", morg_lr_auc)\n",
    "morg_knn_auc = auc_calc(x_morg_val, y_morg_val, knn_morg)\n",
    "print(\"AUC using k-nearest naighbor: \", morg_knn_auc)\n",
    "morg_gb_auc = auc_calc(x_morg_val, y_morg_val, gb_morg)\n",
    "print(\"AUC using gradient boosting: \", morg_gb_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daylight-like fingerprint auc values for all three models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd_lr_auc = auc_calc(x_rd_val, y_rd_val, lr_rd)\n",
    "print(\"AUC using logistic regression: \", rd_lr_auc)\n",
    "rd_knn_auc = auc_calc(x_rd_val, y_rd_val, knn_rd)\n",
    "print(\"AUC using k-nearest neighbor: \", rd_knn_auc)\n",
    "rd_gb_auc = auc_calc(x_rd_val, y_rd_val, gb_rd)\n",
    "print(\"AUC using gradient boosting: \", rd_gb_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atom-pair fingerprint auc values for all three models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AP_lr_auc = auc_calc(x_AP_val, y_AP_val, lr_AP)\n",
    "print(\"AUC using logistic regression: \", AP_lr_auc)\n",
    "AP_knn_auc = auc_calc(x_AP_val, y_AP_val, knn_AP)\n",
    "print(\"AUC using k-nearest naighbor: \", AP_knn_auc)\n",
    "AP_gb_auc = auc_calc(x_AP_val, y_AP_val, gb_AP)\n",
    "print(\"AUC using gradient boosting: \", AP_gb_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topologial torsion fingerprint auc values for all three models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torsion_lr_auc = auc_calc(x_torsion_val, y_torsion_val, lr_torsion)\n",
    "print(\"AUC using logistic regression: \", torsion_lr_auc)\n",
    "torsion_knn_auc = auc_calc(x_torsion_val, y_torsion_val, knn_torsion)\n",
    "print(\"AUC using k-nearest naighbor: \", torsion_knn_auc)\n",
    "torsion_gb_auc = auc_calc(x_torsion_val, y_torsion_val, gb_torsion)\n",
    "print(\"AUC using gradient boosting: \", torsion_gb_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## f1-score\n",
    "\n",
    "The f1-score of a model is calculated using recall (calculated like sensitivity) and precision, which is the rate of:\n",
    "\n",
    "* true positive / (false positive + true positive)\n",
    "\n",
    "The F1-score can then be found using:\n",
    "\n",
    "<img src=\"images/f1.png\">\n",
    "\n",
    "A F1 Score finds a balance between a models recall (fewer predicted points turning out to be false negatives) and precision (fewer predicted points turning out to be false positives).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1score(x_val, y_val, model):\n",
    "    #predictions made on validation data\n",
    "    predictions = model.predict(x_val)\n",
    "    #generating the classification report\n",
    "    clrpt = classification_report(y_val, predictions, output_dict = True)\n",
    "    #accessing the weighted average entery in dictionairy\n",
    "    d = clrpt[\"weighted avg\"]\n",
    "    #calling the f1_score\n",
    "    f1 = d['f1-score']\n",
    "    return 'f1-score %.6f' % f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Morgan fingerprint f-scores for all three models using validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morg_lr_f1 = f1score(x_morg_val, y_morg_val, lr_morg)\n",
    "morg_knn_f1 = f1score(x_morg_val, y_morg_val, knn_morg)\n",
    "morg_gb_f1 = f1score(x_morg_val, y_morg_val, gb_morg)\n",
    "print(morg_lr_f1)\n",
    "print(morg_knn_f1)\n",
    "print(morg_gb_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daylight-like fingerprint f-scores for all three models using validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd_lr_f1 = f1score(x_rd_val, y_rd_val, lr_rd)\n",
    "rd_knn_f1 = f1score(x_rd_val, y_rd_val, knn_rd)\n",
    "rd_gb_f1 = f1score(x_rd_val, y_rd_val, gb_rd)\n",
    "print(rd_lr_f1)\n",
    "print(rd_knn_f1)\n",
    "print(rd_gb_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atom-pair fingerprint f-scores for all three models using validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AP_lr_f1 = f1score(x_AP_val, y_AP_val, lr_AP)\n",
    "AP_knn_f1 = f1score(x_AP_val, y_AP_val, knn_AP)\n",
    "AP_gb_f1 = f1score(x_AP_val, y_AP_val, gb_AP)\n",
    "print(AP_lr_f1)\n",
    "print(AP_knn_f1)\n",
    "print(AP_gb_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topological torsion fingerprint f-scores for all three models using validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torsion_lr_f1 = f1score(x_torsion_val, y_torsion_val, lr_torsion)\n",
    "torsion_knn_f1 = f1score(x_torsion_val, y_torsion_val, knn_torsion)\n",
    "torsion_gb_f1 = f1score(x_torsion_val, y_torsion_val, gb_torsion)\n",
    "print(torsion_lr_f1)\n",
    "print(torsion_knn_f1)\n",
    "print(torsion_gb_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results and conclusion\n",
    "\n",
    "The table below shows the predictive power of each classifier when using the four fingerprints. Metrics included are accuracy scores are shown for training, test, and validation data sets, AUC scores for validation data, and the f1 scores of the validation data. The highest scores are highlighted in green for each fingerprint and classifier.\n",
    "\n",
    "<img src=\"images/conclusion_table.png\">\n",
    "\n",
    "## Which is the best classifier?\n",
    "\n",
    "When looking at validation accuracy, logistic regression has the consistently highest scores. Next, when evaluating AUC - arguably the most important metric - gradient boosting produced the highest score but logistic regression had the highest average scores. Lastly, the highest individual and average f1-scores belong to logistic regression, suggesting that it produces models with the greatest balance between precision and robustness.\n",
    "\n",
    "### winner: Logistic regression\n",
    "\n",
    "## Which is the best fingerprint?\n",
    "\n",
    "Literature suggests that although topological torsion may not be as popular as the Daylight-like and Morgan fingerprints, they show higher performance in comparison to other finger­prints [8].\n",
    "The results show that the Daylight-like fingerprint had the highest AUC score for both logistic regression and knn - the Atom-pair fingerprint scored only marginally higher when using gradient boosting. However when looking at gradient boosting, Atom-pair fingerprints outscored the Daylight-like fingerprints in validation accuracy, AUC, and F1-scores.\n",
    "\n",
    "### winner: Daylight-like fingerprint\n",
    "\n",
    "## Possible issues\n",
    "\n",
    "Sometimes accidental collisions between patterns can occur in fingerprints due to similar molecular substructures. This happens when the same bit is set by multiple patterns (hashing a specific feature of two similar structures as the same bit). For example, the topological torsion fingerprint produced eight identical fingerprints, this can be avoided by increasing the bit length (from 2048 to 4096)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
