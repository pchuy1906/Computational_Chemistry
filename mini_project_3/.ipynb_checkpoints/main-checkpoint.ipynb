{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Advanced in silico drug design workshop. Olomouc, 30 January - 1 February, 2017.\n",
    "### QSAR tutorial.\n",
    "Dr. Pavel Polishchuk  \n",
    "   \n",
    "Institute of Molecular and Translational Medicine, Faculty of Medicine and Dentistry, Palacký University and University Hospital in Olomouc, Hněvotínská 1333/5, 779 00 Olomouc, Czech Republic  \n",
    "http://imtm.cz  \n",
    "http://qsar4u.com  \n",
    "pavel_polishchuk@ukr.net  \n",
    "pavlo.polishchuk@upol.cz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import AllChem, Descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from rdkit.Chem.Draw import IPythonConsole\n",
    "# from rdkit.Chem import Draw\n",
    "# IPythonConsole.ipython_useSVG=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, matthews_corrcoef\n",
    "#from sklearn.externals import joblib\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading molecules and activity from SDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of molecule is  321\n"
     ]
    }
   ],
   "source": [
    "fname = \"data/logBB.sdf\"\n",
    "\n",
    "mols = []\n",
    "y = []\n",
    "for mol in Chem.SDMolSupplier(fname):\n",
    "    if mol is not None:\n",
    "        mols.append(mol)\n",
    "        y.append(mol.GetIntProp(\"logBB_class\"))\n",
    "\n",
    "nmol = len(mols)\n",
    "print (\"The number of molecule is \", nmol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate descriptors (fingerprints) and convert them into numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate binary Morgan fingerprint with radius 2\n",
    "fp = [AllChem.GetMorganFingerprintAsBitVect(m, 2) for m in mols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_dist = np.zeros((nmol,nmol))\n",
    "for imol1 in range(nmol):\n",
    "    for imol2 in range(imol1+1,nmol):\n",
    "        sim_dist[imol1,imol2] = DataStructs.DiceSimilarity(fp[imol1],fp[imol2])\n",
    "        sim_dist[imol2,imol1] = sim_dist[imol1,imol2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import seaborn as sns\n",
    "#import matplotlib.pyplot as plt\n",
    "#plt.figure(figsize = (20,16))\n",
    "#sns.heatmap(sim_dist, cmap=\"YlGnBu\", annot=True, fmt=\".1f\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rdkit_numpy_convert(fp):\n",
    "    output = []\n",
    "    for f in fp:\n",
    "        arr = np.zeros((1,))\n",
    "        DataStructs.ConvertToNumpyArray(f, arr)\n",
    "        output.append(arr)\n",
    "    return np.asarray(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = rdkit_numpy_convert(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(321, 2048)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5545171339563862"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check wether the data set is balanced\n",
    "sum(y) / len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the whole set on training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed to make all further calculations reproducible\n",
    "seed = 42\n",
    "# randomly select 20% of compounds as test set\n",
    "indices = np.arange(len(y))\n",
    "\n",
    "x_tr, x_ts, y_tr, y_ts, idx1, idx2 = train_test_split(x, y, indices, test_size=0.20, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ts = []\n",
    "for idtest in idx2:\n",
    "    numerator_   = y_tr[:] * sim_dist[idtest,idx1]\n",
    "    denominator_ = sim_dist[idtest,idx1]\n",
    "    y_pred_ts.append( int(round(sum(numerator_)/sum(denominator_))) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.7230769230769231\n",
      "MCC =  0.47559486560567094\n",
      "Kappa =  0.3689320388349514\n"
     ]
    }
   ],
   "source": [
    "# calc statistics\n",
    "print(\"Accuracy = \", accuracy_score(y_ts, y_pred_ts))\n",
    "print(\"MCC = \", matthews_corrcoef(y_ts, y_pred_ts))\n",
    "print(\"Kappa = \", cohen_kappa_score(y_ts, y_pred_ts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create folds for cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, random_state=seed, shuffle=True)\n",
    "#cv = StratifiedKFold(n_splits=5, random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold_1\n",
      "TRAIN: [  0   1   2   3   4   5   7   8  10  13  14  15  16  18  19  21  22  23\n",
      "  24  25  26  27  28  30  32  36  37  38  39  40  42  43  44  45  46  47\n",
      "  48  49  52  53  55  56  58  59  61  63  64  65  66  67  68  69  70  71\n",
      "  72  73  75  76  78  79  80  82  83  84  85  86  87  88  89  90  92  93\n",
      "  95  96  97  98  99 100 101 103 104 105 106 108 109 112 114 115 116 117\n",
      " 118 119 120 122 123 124 125 126 127 128 129 130 131 132 134 135 136 137\n",
      " 138 139 140 142 143 144 145 146 147 148 149 150 153 154 157 158 159 160\n",
      " 161 162 163 165 166 167 168 169 170 171 173 174 175 176 177 178 179 180\n",
      " 181 182 183 184 185 186 187 188 189 190 191 193 194 195 196 197 198 199\n",
      " 200 201 203 204 205 206 207 208 209 211 212 213 214 215 216 217 218 219\n",
      " 220 221 222 223 224 226 229 231 232 233 234 235 236 237 238 241 242 244\n",
      " 246 247 248 250 251 255]\n",
      "TEST: [  6   9  11  12  17  20  29  31  33  34  35  41  50  51  54  57  60  62\n",
      "  74  77  81  91  94 102 107 110 111 113 121 133 141 151 152 155 156 164\n",
      " 172 192 202 210 225 227 228 230 239 240 243 245 249 252 253 254]\n",
      "\n",
      "Fold_2\n",
      "TRAIN: [  0   1   4   6   7   8   9  10  11  12  13  14  15  16  17  18  20  21\n",
      "  22  23  24  25  27  28  29  30  31  32  33  34  35  36  39  40  41  42\n",
      "  43  46  47  48  49  50  51  53  54  55  56  57  58  59  60  61  62  63\n",
      "  64  65  67  70  71  72  73  74  77  78  80  81  82  83  85  86  87  89\n",
      "  90  91  92  94  95  96  97  98  99 102 103 104 105 106 107 109 110 111\n",
      " 113 114 115 116 117 118 119 121 122 123 125 127 128 129 131 132 133 134\n",
      " 135 137 140 141 143 144 145 146 147 148 149 150 151 152 153 154 155 156\n",
      " 158 159 160 161 162 163 164 167 168 169 170 171 172 175 176 178 180 181\n",
      " 182 184 185 186 187 188 190 191 192 194 198 199 200 202 203 204 205 206\n",
      " 207 208 210 211 212 213 214 215 216 217 219 221 222 223 224 225 227 228\n",
      " 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 247 248\n",
      " 249 250 251 252 253 254 255]\n",
      "TEST: [  2   3   5  19  26  37  38  44  45  52  66  68  69  75  76  79  84  88\n",
      "  93 100 101 108 112 120 124 126 130 136 138 139 142 157 165 166 173 174\n",
      " 177 179 183 189 193 195 196 197 201 209 218 220 226 229 246]\n",
      "\n",
      "Fold_3\n",
      "TRAIN: [  0   2   3   4   5   6   7   8   9  10  11  12  13  16  17  18  19  20\n",
      "  21  22  24  26  29  30  31  33  34  35  36  37  38  39  40  41  42  44\n",
      "  45  46  48  50  51  52  53  54  55  56  57  58  60  61  62  63  64  65\n",
      "  66  67  68  69  70  72  74  75  76  77  78  79  81  82  84  85  86  88\n",
      "  89  90  91  92  93  94  95  98 100 101 102 107 108 110 111 112 113 115\n",
      " 119 120 121 122 124 125 126 128 129 130 132 133 134 135 136 137 138 139\n",
      " 140 141 142 145 146 147 148 149 150 151 152 153 154 155 156 157 159 160\n",
      " 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 177 179 180\n",
      " 181 183 185 186 188 189 191 192 193 194 195 196 197 198 200 201 202 203\n",
      " 204 205 207 209 210 211 212 216 217 218 220 222 223 224 225 226 227 228\n",
      " 229 230 231 232 233 234 236 237 238 239 240 241 243 244 245 246 247 248\n",
      " 249 250 251 252 253 254 255]\n",
      "TEST: [  1  14  15  23  25  27  28  32  43  47  49  59  71  73  80  83  87  96\n",
      "  97  99 103 104 105 106 109 114 116 117 118 123 127 131 143 144 158 176\n",
      " 178 182 184 187 190 199 206 208 213 214 215 219 221 235 242]\n",
      "\n",
      "Fold_4\n",
      "TRAIN: [  1   2   3   4   5   6   9  10  11  12  13  14  15  17  19  20  23  24\n",
      "  25  26  27  28  29  30  31  32  33  34  35  37  38  39  41  42  43  44\n",
      "  45  46  47  49  50  51  52  53  54  55  57  58  59  60  61  62  66  67\n",
      "  68  69  71  72  73  74  75  76  77  79  80  81  83  84  85  86  87  88\n",
      "  89  90  91  93  94  96  97  99 100 101 102 103 104 105 106 107 108 109\n",
      " 110 111 112 113 114 116 117 118 119 120 121 122 123 124 126 127 130 131\n",
      " 132 133 136 137 138 139 141 142 143 144 146 147 149 150 151 152 154 155\n",
      " 156 157 158 159 160 161 164 165 166 168 169 171 172 173 174 176 177 178\n",
      " 179 180 181 182 183 184 185 187 189 190 191 192 193 195 196 197 198 199\n",
      " 201 202 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219\n",
      " 220 221 224 225 226 227 228 229 230 233 235 236 237 238 239 240 242 243\n",
      " 245 246 248 249 252 253 254]\n",
      "TEST: [  0   7   8  16  18  21  22  36  40  48  56  63  64  65  70  78  82  92\n",
      "  95  98 115 125 128 129 134 135 140 145 148 153 162 163 167 170 175 186\n",
      " 188 194 200 203 222 223 231 232 234 241 244 247 250 251 255]\n",
      "\n",
      "Fold_5\n",
      "TRAIN: [  0   1   2   3   5   6   7   8   9  11  12  14  15  16  17  18  19  20\n",
      "  21  22  23  25  26  27  28  29  31  32  33  34  35  36  37  38  40  41\n",
      "  43  44  45  47  48  49  50  51  52  54  56  57  59  60  62  63  64  65\n",
      "  66  68  69  70  71  73  74  75  76  77  78  79  80  81  82  83  84  87\n",
      "  88  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 120 121 123 124 125 126 127\n",
      " 128 129 130 131 133 134 135 136 138 139 140 141 142 143 144 145 148 151\n",
      " 152 153 155 156 157 158 162 163 164 165 166 167 170 172 173 174 175 176\n",
      " 177 178 179 182 183 184 186 187 188 189 190 192 193 194 195 196 197 199\n",
      " 200 201 202 203 206 208 209 210 213 214 215 218 219 220 221 222 223 225\n",
      " 226 227 228 229 230 231 232 234 235 239 240 241 242 243 244 245 246 247\n",
      " 249 250 251 252 253 254 255]\n",
      "TEST: [  4  10  13  24  30  39  42  46  53  55  58  61  67  72  85  86  89  90\n",
      " 119 122 132 137 146 147 149 150 154 159 160 161 168 169 171 180 181 185\n",
      " 191 198 204 205 207 211 212 216 217 224 233 236 237 238 248]\n"
     ]
    }
   ],
   "source": [
    "# print out ids of folds\n",
    "for i, (train_index, test_index) in enumerate(cv.split(x_tr, y_tr)):\n",
    "    print(\"\\nFold_\" + str(i+1))\n",
    "    print(\"TRAIN:\", train_index)\n",
    "    print(\"TEST:\", test_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step may be crucial for certain modeling approaches lke SVM.\n",
    "In the case of binary fingerprints it may be less useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain scale object which can be further applied to scale any data to fit the training set\n",
    "scale = StandardScaler().fit(x_tr)\n",
    "x_tr = scale.transform(x_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/logBB_scale.pkl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it is a good idea to save it for future use\n",
    "joblib.dump(scale, \"data/logBB_scale.pkl\", compress=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Search for optimal tuning parameters and build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create grid search dictionary\n",
    "param_grid = {\"max_features\": [x_tr.shape[1] // 10, x_tr.shape[1] // 7, x_tr.shape[1] // 5, x_tr.shape[1] // 3], \n",
    "              \"n_estimators\": [100, 250, 500]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup model building\n",
    "m = GridSearchCV(RandomForestClassifier(), param_grid, n_jobs=2, cv=cv, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=RandomForestClassifier(), n_jobs=2,\n",
       "             param_grid={'max_features': [204, 292, 409, 682],\n",
       "                         'n_estimators': [100, 250, 500]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run model building\n",
    "m.fit(x_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 409, 'n_estimators': 250}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7930618401206637"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.3726531 , 0.94125042, 1.86414795, 0.42256985, 1.07519417,\n",
       "        2.06206431, 0.45674996, 1.12906709, 2.36443071, 0.54995298,\n",
       "        1.36331973, 2.6553659 ]),\n",
       " 'std_fit_time': array([0.00682861, 0.01659201, 0.00891853, 0.00425554, 0.04639724,\n",
       "        0.03559016, 0.00879766, 0.01075677, 0.12509904, 0.01731615,\n",
       "        0.02930505, 0.10850422]),\n",
       " 'mean_score_time': array([0.01633573, 0.03574929, 0.06963158, 0.01531549, 0.03612938,\n",
       "        0.0700232 , 0.01908917, 0.03630486, 0.06861701, 0.01784372,\n",
       "        0.03502479, 0.06704721]),\n",
       " 'std_score_time': array([0.00174539, 0.00032462, 0.00111462, 0.00031887, 0.00177013,\n",
       "        0.00210879, 0.00757407, 0.00140344, 0.00053619, 0.00530548,\n",
       "        0.00021557, 0.00282347]),\n",
       " 'param_max_features': masked_array(data=[204, 204, 204, 292, 292, 292, 409, 409, 409, 682, 682,\n",
       "                    682],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[100, 250, 500, 100, 250, 500, 100, 250, 500, 100, 250,\n",
       "                    500],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'max_features': 204, 'n_estimators': 100},\n",
       "  {'max_features': 204, 'n_estimators': 250},\n",
       "  {'max_features': 204, 'n_estimators': 500},\n",
       "  {'max_features': 292, 'n_estimators': 100},\n",
       "  {'max_features': 292, 'n_estimators': 250},\n",
       "  {'max_features': 292, 'n_estimators': 500},\n",
       "  {'max_features': 409, 'n_estimators': 100},\n",
       "  {'max_features': 409, 'n_estimators': 250},\n",
       "  {'max_features': 409, 'n_estimators': 500},\n",
       "  {'max_features': 682, 'n_estimators': 100},\n",
       "  {'max_features': 682, 'n_estimators': 250},\n",
       "  {'max_features': 682, 'n_estimators': 500}],\n",
       " 'split0_test_score': array([0.76923077, 0.76923077, 0.76923077, 0.75      , 0.78846154,\n",
       "        0.76923077, 0.75      , 0.76923077, 0.78846154, 0.75      ,\n",
       "        0.76923077, 0.76923077]),\n",
       " 'split1_test_score': array([0.78431373, 0.74509804, 0.80392157, 0.76470588, 0.76470588,\n",
       "        0.76470588, 0.82352941, 0.82352941, 0.78431373, 0.80392157,\n",
       "        0.82352941, 0.80392157]),\n",
       " 'split2_test_score': array([0.7254902 , 0.7254902 , 0.76470588, 0.7254902 , 0.74509804,\n",
       "        0.74509804, 0.76470588, 0.74509804, 0.7254902 , 0.74509804,\n",
       "        0.7254902 , 0.74509804]),\n",
       " 'split3_test_score': array([0.80392157, 0.82352941, 0.80392157, 0.80392157, 0.80392157,\n",
       "        0.80392157, 0.80392157, 0.82352941, 0.84313725, 0.78431373,\n",
       "        0.82352941, 0.8627451 ]),\n",
       " 'split4_test_score': array([0.78431373, 0.78431373, 0.76470588, 0.7254902 , 0.78431373,\n",
       "        0.80392157, 0.80392157, 0.80392157, 0.78431373, 0.78431373,\n",
       "        0.78431373, 0.76470588]),\n",
       " 'mean_test_score': array([0.773454  , 0.76953243, 0.78129713, 0.75392157, 0.77730015,\n",
       "        0.77737557, 0.78921569, 0.79306184, 0.78514329, 0.77352941,\n",
       "        0.7852187 , 0.78914027]),\n",
       " 'std_test_score': array([0.02639129, 0.03367791, 0.01854652, 0.02914915, 0.02038656,\n",
       "        0.02314337, 0.02738086, 0.0311221 , 0.03724024, 0.0224422 ,\n",
       "        0.03676778, 0.0413988 ]),\n",
       " 'rank_test_score': array([10, 11,  6, 12,  8,  7,  2,  1,  5,  9,  4,  3], dtype=int32)}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.773454  , 0.76953243, 0.78129713, 0.75392157, 0.77730015,\n",
       "       0.77737557, 0.78921569, 0.79306184, 0.78514329, 0.77352941,\n",
       "       0.7852187 , 0.78914027])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'max_features': 204, 'n_estimators': 100},\n",
       " {'max_features': 204, 'n_estimators': 250},\n",
       " {'max_features': 204, 'n_estimators': 500},\n",
       " {'max_features': 292, 'n_estimators': 100},\n",
       " {'max_features': 292, 'n_estimators': 250},\n",
       " {'max_features': 292, 'n_estimators': 500},\n",
       " {'max_features': 409, 'n_estimators': 100},\n",
       " {'max_features': 409, 'n_estimators': 250},\n",
       " {'max_features': 409, 'n_estimators': 500},\n",
       " {'max_features': 682, 'n_estimators': 100},\n",
       " {'max_features': 682, 'n_estimators': 250},\n",
       " {'max_features': 682, 'n_estimators': 500}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.cv_results_['params']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/logBB_rf_morgan.pkl']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(m, \"data/logBB_rf_morgan.pkl\", compress=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Predict test set compounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load scale if necessary\n",
    "scale = joblib.load(\"data/logBB_scale.pkl\")\n",
    "\n",
    "# scale descriptors of the test set compounds\n",
    "x_ts = scale.transform(x_ts)\n",
    "\n",
    "# predict logBB class\n",
    "pred_rf = m.predict(x_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.7538461538461538\n",
      "MCC =  0.4995357946109721\n",
      "Kappa =  0.4985535197685632\n"
     ]
    }
   ],
   "source": [
    "# calc statistics\n",
    "print(\"Accuracy = \", accuracy_score(y_ts, pred_rf))\n",
    "print(\"MCC = \", matthews_corrcoef(y_ts, pred_rf))\n",
    "print(\"Kappa = \", cohen_kappa_score(y_ts, pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### applicability domain estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the model includes several ones like RF models or consensus models (or for probabilistic models)\n",
    "# we can calculate consistency of predictions amongs those models and use it for estimation of applicability domain\n",
    "pred_prob = m.predict_proba(x_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.892, 0.108],\n",
       "       [0.208, 0.792],\n",
       "       [0.3  , 0.7  ],\n",
       "       [0.196, 0.804],\n",
       "       [0.396, 0.604],\n",
       "       [0.224, 0.776],\n",
       "       [0.004, 0.996],\n",
       "       [0.016, 0.984],\n",
       "       [0.872, 0.128],\n",
       "       [0.928, 0.072],\n",
       "       [0.244, 0.756],\n",
       "       [0.812, 0.188],\n",
       "       [0.584, 0.416],\n",
       "       [0.908, 0.092],\n",
       "       [0.384, 0.616],\n",
       "       [0.568, 0.432],\n",
       "       [0.14 , 0.86 ],\n",
       "       [0.012, 0.988],\n",
       "       [0.008, 0.992],\n",
       "       [0.152, 0.848],\n",
       "       [0.556, 0.444],\n",
       "       [0.   , 1.   ],\n",
       "       [0.196, 0.804],\n",
       "       [0.556, 0.444],\n",
       "       [0.256, 0.744],\n",
       "       [0.38 , 0.62 ],\n",
       "       [0.636, 0.364],\n",
       "       [0.308, 0.692],\n",
       "       [0.768, 0.232],\n",
       "       [0.656, 0.344],\n",
       "       [0.012, 0.988],\n",
       "       [0.948, 0.052],\n",
       "       [0.112, 0.888],\n",
       "       [0.692, 0.308],\n",
       "       [0.324, 0.676],\n",
       "       [0.612, 0.388],\n",
       "       [0.924, 0.076],\n",
       "       [0.78 , 0.22 ],\n",
       "       [0.66 , 0.34 ],\n",
       "       [0.   , 1.   ],\n",
       "       [0.876, 0.124],\n",
       "       [0.   , 1.   ],\n",
       "       [0.38 , 0.62 ],\n",
       "       [0.544, 0.456],\n",
       "       [0.216, 0.784],\n",
       "       [0.732, 0.268],\n",
       "       [0.236, 0.764],\n",
       "       [0.72 , 0.28 ],\n",
       "       [0.   , 1.   ],\n",
       "       [0.272, 0.728],\n",
       "       [0.684, 0.316],\n",
       "       [0.184, 0.816],\n",
       "       [0.4  , 0.6  ],\n",
       "       [0.612, 0.388],\n",
       "       [0.792, 0.208],\n",
       "       [0.828, 0.172],\n",
       "       [0.668, 0.332],\n",
       "       [0.128, 0.872],\n",
       "       [0.928, 0.072],\n",
       "       [0.016, 0.984],\n",
       "       [0.012, 0.988],\n",
       "       [0.172, 0.828],\n",
       "       [0.852, 0.148],\n",
       "       [0.304, 0.696],\n",
       "       [0.028, 0.972]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# probablity\n",
    "pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup threshold\n",
    "threshold = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc maximum predicted probability for each row (compound) and compare to the threshold\n",
    "da = np.amax(pred_prob, axis=1) > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False, False,  True, False, False,  True,  True,  True,\n",
       "        True, False,  True, False,  True, False, False,  True,  True,\n",
       "        True,  True, False,  True,  True, False, False, False, False,\n",
       "       False, False, False,  True,  True,  True, False, False, False,\n",
       "        True, False, False,  True,  True,  True, False, False, False,\n",
       "       False, False, False,  True, False, False,  True, False, False,\n",
       "       False,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "       False,  True])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.9032258064516129\n",
      "MCC =  0.7947695843356161\n",
      "Kappa =  0.7928730512249443\n"
     ]
    }
   ],
   "source": [
    "# calc statistics\n",
    "print(\"Accuracy = \", accuracy_score(np.asarray(y_ts)[da], pred_rf[da]))\n",
    "print(\"MCC = \", matthews_corrcoef(np.asarray(y_ts)[da], pred_rf[da]))\n",
    "print(\"Kappa = \", cohen_kappa_score(np.asarray(y_ts)[da], pred_rf[da]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47692307692307695"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calc coverage\n",
    "sum(da) / len(da)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create grid search dictionary\n",
    "param_grid = {\"C\": [10 ** i for i in range(0, 5)],\n",
    "              \"gamma\": [10 ** i for i in range(-6, 0)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup model building\n",
    "svm = GridSearchCV(SVC(kernel='rbf', probability=True), param_grid, n_jobs=2, cv=cv, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=SVC(probability=True), n_jobs=2,\n",
       "             param_grid={'C': [1, 10, 100, 1000, 10000],\n",
       "                         'gamma': [1e-06, 1e-05, 0.0001, 0.001, 0.01, 0.1]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run model building\n",
    "svm.fit(x_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7540723981900452"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 100, 'gamma': 1e-05}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/logBB_svm_morgan.pkl']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save model\n",
    "joblib.dump(svm, \"data/logBB_svm_morgan.pkl\", compress=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict logBB for the test set compounds\n",
    "pred_svm = svm.predict(x_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.7846153846153846\n",
      "MCC =  0.5525513059108836\n",
      "Kappa =  0.5417925478348439\n"
     ]
    }
   ],
   "source": [
    "# calc statistics\n",
    "print(\"Accuracy = \", accuracy_score(y_ts, pred_svm))\n",
    "print(\"MCC = \", matthews_corrcoef(y_ts, pred_svm))\n",
    "print(\"Kappa = \", cohen_kappa_score(y_ts, pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate applicability domain and calc stat\n",
    "pred_prob = svm.predict_proba(x_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = np.amax(pred_prob, axis=1) > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.8571428571428571\n",
      "MCC =  0.7071067811865475\n",
      "Kappa =  0.7058823529411764\n",
      "Coverage =  0.5384615384615384\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy = \", accuracy_score(np.asarray(y_ts)[da], pred_svm[da]))\n",
    "print(\"MCC = \", matthews_corrcoef(np.asarray(y_ts)[da], pred_svm[da]))\n",
    "print(\"Kappa = \", cohen_kappa_score(np.asarray(y_ts)[da], pred_svm[da]))\n",
    "print(\"Coverage = \", sum(da) / len(da))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build the third model (GBM) compute consensus predictions from RF, and SVM models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup model building\n",
    "param_grid = {\"n_estimators\": [100, 200, 300, 400, 500]}\n",
    "gbm = GridSearchCV(GradientBoostingClassifier(subsample=0.5, max_features=0.5), \n",
    "                   param_grid, n_jobs=2, cv=cv, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=GradientBoostingClassifier(max_features=0.5,\n",
       "                                                  subsample=0.5),\n",
       "             n_jobs=2, param_grid={'n_estimators': [100, 200, 300, 400, 500]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run model building\n",
    "gbm.fit(x_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7774509803921568"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 100}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_gbm = gbm.predict(x_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.7230769230769231\n",
      "MCC =  0.4245166957273495\n",
      "Kappa =  0.4236453201970444\n"
     ]
    }
   ],
   "source": [
    "# calc statistics\n",
    "print(\"Accuracy = \", accuracy_score(y_ts, pred_gbm))\n",
    "print(\"MCC = \", matthews_corrcoef(y_ts, pred_gbm))\n",
    "print(\"Kappa = \", cohen_kappa_score(y_ts, pred_gbm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### consensus model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_c = 1 * (((pred_rf + pred_svm + pred_gbm) / 3) >= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.7384615384615385\n",
      "MCC =  0.45883146774112354\n",
      "Kappa =  0.4585987261146497\n"
     ]
    }
   ],
   "source": [
    "# calc statistics\n",
    "print(\"Accuracy = \", accuracy_score(y_ts, pred_c))\n",
    "print(\"MCC = \", matthews_corrcoef(y_ts, pred_c))\n",
    "print(\"Kappa = \", cohen_kappa_score(y_ts, pred_c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Add to Morgan fingerprints some other descriptors and look at the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc some descriptors\n",
    "descr = []\n",
    "for m in mols:\n",
    "    descr.append([Descriptors.MolLogP(m),\n",
    "                  Descriptors.TPSA(m),\n",
    "                  Descriptors.NHOHCount(m),\n",
    "                  Descriptors.NOCount(m),\n",
    "                  Descriptors.NumHAcceptors(m),\n",
    "                  Descriptors.NumHDonors(m),\n",
    "                  Descriptors.NumRotatableBonds(m),\n",
    "                  Descriptors.NumHeteroatoms(m),\n",
    "                  Descriptors.FractionCSP3(m)])\n",
    "descr = np.asarray(descr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(321, 9)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add them to morgan fingerprints\n",
    "x = np.concatenate((x, descr), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(321, 2057)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly select 20% of compounds as test set\n",
    "x_tr, x_ts, y_tr, y_ts = train_test_split(x, y, test_size=0.20, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = StandardScaler().fit(x_tr)\n",
    "x_tr = scale.transform(x_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create grid search dictionary\n",
    "param_grid = {\"max_features\": [x_tr.shape[1] // 10, x_tr.shape[1] // 7, x_tr.shape[1] // 5, x_tr.shape[1] // 3], \n",
    "              \"n_estimators\": [100, 250, 500]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup model building\n",
    "m = GridSearchCV(RandomForestClassifier(), param_grid, n_jobs=2, cv=cv, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n",
       "             estimator=RandomForestClassifier(), n_jobs=2,\n",
       "             param_grid={'max_features': [205, 293, 411, 685],\n",
       "                         'n_estimators': [100, 250, 500]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run model building\n",
    "m.fit(x_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8202865761689291"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale descriptors of the test set compounds\n",
    "x_ts = scale.transform(x_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict logBB for the test set compounds\n",
    "pred = m.predict(x_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.8769230769230769\n",
      "MCC =  0.7473270325025954\n",
      "Kappa =  0.7410358565737052\n"
     ]
    }
   ],
   "source": [
    "# calc statistics\n",
    "print(\"Accuracy = \", accuracy_score(y_ts, pred))\n",
    "print(\"MCC = \", matthews_corrcoef(y_ts, pred))\n",
    "print(\"Kappa = \", cohen_kappa_score(y_ts, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate applicability domain and calc stat\n",
    "pred_prob = m.predict_proba(x_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = np.amax(pred_prob, axis=1) > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.9444444444444444\n",
      "MCC =  0.8864052604279183\n",
      "Kappa =  0.88\n",
      "Coverage =  0.5538461538461539\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy = \", accuracy_score(np.asarray(y_ts)[da], pred[da]))\n",
    "print(\"MCC = \", matthews_corrcoef(np.asarray(y_ts)[da], pred[da]))\n",
    "print(\"Kappa = \", cohen_kappa_score(np.asarray(y_ts)[da], pred[da]))\n",
    "print(\"Coverage = \", sum(da) / len(da))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has a better accuracy. Added descritors improved the model predictivity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Let's try to analyse which variables are the most important in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_features=293, n_estimators=500, random_state=42)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rebuild RF model manually using best parameters to be able to extract additional information from the model\n",
    "rf = RandomForestClassifier(n_estimators=m.best_params_[\"n_estimators\"], \n",
    "                           max_features=m.best_params_[\"max_features\"],\n",
    "                           random_state=seed)\n",
    "rf.fit(x_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.00211988, 0.00034081, ..., 0.01004565, 0.03644454,\n",
       "       0.02356641])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 2049 (0.118598)\n",
      "2. feature 2051 (0.055542)\n",
      "3. feature 2048 (0.048918)\n",
      "4. feature 2055 (0.036445)\n",
      "5. feature 650 (0.035974)\n",
      "6. feature 2052 (0.033922)\n",
      "7. feature 2056 (0.023566)\n",
      "8. feature 2050 (0.019445)\n",
      "9. feature 2053 (0.017630)\n",
      "10. feature 807 (0.012406)\n"
     ]
    }
   ],
   "source": [
    "indices = np.argsort(imp)[::-1]\n",
    "\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "# print top 10 features\n",
    "for i in range(10):\n",
    "    print(\"%d. feature %d (%f)\" % (i + 1, indices[i], imp[indices[i]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2049 - MolLogP  \n",
    "2050 - TPSA(m)  \n",
    "2051 - NHOHCount  \n",
    "2052 - NOCount \n",
    "2053 - NumHAcceptors  \n",
    "2054 - NumHDonors  \n",
    "2055 - NumRotatableBonds  \n",
    "2056 - NumHeteroatoms  \n",
    "2057 - FractionCSP3\n",
    "\n",
    "features with numbers 1-2048 are different Morgan fingerprints  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
